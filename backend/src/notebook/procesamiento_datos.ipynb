{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPERADOR\\AppData\\Local\\Temp\\ipykernel_8176\\2563690654.py:2: DtypeWarning: Columns (7,14,17,18,21,28,39,42,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"L_STMaestroPrd.csv\")\n",
      "C:\\Users\\OPERADOR\\AppData\\Local\\Temp\\ipykernel_8176\\2563690654.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_MasterProductos[\"descrip1_descrip2\"] = data_MasterProductos[\"descrip1\"].fillna('') + \" \" + data_MasterProductos[\"descrip2\"].fillna('')\n"
     ]
    }
   ],
   "source": [
    "#Carga de datos CSV \n",
    "data = pd.read_csv(\"L_STMaestroPrd.csv\")\n",
    "data.columns[data.isna().all()]\n",
    "data_MasterProductos = data.dropna(axis=1, how='all')\n",
    "data_MasterProductos[\"descrip1_descrip2\"] = data_MasterProductos[\"descrip1\"].fillna('') + \" \" + data_MasterProductos[\"descrip2\"].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPERADOR\\AppData\\Local\\Temp\\ipykernel_8176\\2465150903.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_MasterProductos[nombre_columna] = data_MasterProductos[nombre_columna].apply(normalizar)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def procesar_descripcion(data, nombre_columna):\n",
    "    # Función para normalizar la descripción\n",
    "    def normalizar(texto):\n",
    "        # Asegurar que el texto sea un string\n",
    "        texto = str(texto).strip().lower()\n",
    "        \n",
    "        # 1. Eliminar espacios redundantes\n",
    "        texto = re.sub(r'\\s+', ' ', texto)\n",
    "\n",
    "        # 2. Remover caracteres especiales excepto letras, números, espacios y '%'\n",
    "        texto = re.sub(r'[^a-zA-Z0-9\\s%]', '', texto)\n",
    "\n",
    "        # 3. Separar números de letras y letras de números (ej: 420mm -> 420 mm, mg250 -> mg 250)\n",
    "        texto = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', texto)\n",
    "        texto = re.sub(r'([a-zA-Z])(\\d)', r'\\1 \\2', texto)\n",
    "\n",
    "        # 4. Manejo de 'x':\n",
    "        #    a) Agregar espacios alrededor de la 'x' usada como separador (ej: 10x10 -> 10 x 10)\n",
    "        texto = re.sub(r'(?<=\\d)x(?=\\d)', r' x ', texto)\n",
    "        #    b) Separar 'x' de los números en casos como 'x15' o 'x4'\n",
    "        texto = re.sub(r'\\b[xX](\\d+)', r'x \\1', texto)\n",
    "\n",
    "        # 5. Reemplazar separadores como guiones o barras con espacios\n",
    "        texto = re.sub(r'[-/]', ' ', texto)\n",
    "\n",
    "        # 6. Normalizar términos específicos combinados que terminan en 'x'\n",
    "        combinaciones = {\n",
    "            'tabx': 'tab x',\n",
    "            'compx': 'comp x',\n",
    "            'locx': 'loc x',\n",
    "            'comprecx': 'comprec x',\n",
    "            'capsx': 'caps x',\n",
    "            'jabx': 'jab x',\n",
    "            'pdax': 'pda x',\n",
    "            'pvox': 'pvo x',\n",
    "            'fcocvlvdosifx': 'fcocvlvdosif x',\n",
    "            'sobx': 'sob x',\n",
    "            'crx': 'cr x'\n",
    "        }\n",
    "        for key, val in combinaciones.items():\n",
    "            texto = re.sub(rf'\\b{key}\\b', val, texto)\n",
    "\n",
    "        # 7. Remover palabras repetidas consecutivas (ej: \"paracetamol paracetamol\")\n",
    "        texto = ' '.join(sorted(set(texto.split()), key=texto.split().index))\n",
    "\n",
    "        # 8. Manejo de unidades (ej: \"10mg\" y \"10 mg\" -> \"10 mg\")\n",
    "        texto = re.sub(r'(\\d+)\\s*([a-zA-Z]+)', r'\\1 \\2', texto)\n",
    "\n",
    "        # 9. Eliminar espacios redundantes nuevamente para garantizar limpieza\n",
    "        texto = texto.strip()\n",
    "\n",
    "        return texto\n",
    "\n",
    "    # Aplicar la función 'normalizar' a cada elemento de la columna\n",
    "    data_MasterProductos[nombre_columna] = data_MasterProductos[nombre_columna].apply(normalizar)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "data_MasterProductos = procesar_descripcion(data_MasterProductos, \"descrip1_descrip2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "\n",
    "\n",
    "#Cargar tokenizador y modelo preentrenado\n",
    "modelo_base = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo_base)\n",
    "model = BertModel.from_pretrained(modelo_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OPERADOR\\AppData\\Local\\Temp\\ipykernel_8176\\801250840.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_MasterProductos[\"token\"] = data_MasterProductos[\"descrip1_descrip2\"].apply(lambda x: tokenizer.tokenize(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3330    [amo, ##xid, ##al, du, ##o, gt, ##s, ##x, 15, ml]\n",
       "3331    [amo, ##xid, ##al, du, ##o, mu, ##c, compre, #...\n",
       "3332    [amo, ##xid, ##al, du, ##o, sus, ##p, ##x, 120...\n",
       "3333    [amo, ##xid, ##al, du, ##o, sus, ##p, ##x, 7, ...\n",
       "3334             [amo, ##xid, ##al, gt, ##s, ##x, 15, ml]\n",
       "3335    [amo, ##xid, ##al, ped, 125, mg, sus, ##p, ##x...\n",
       "3336    [amo, ##xid, ##al, ped, 250, mg, sus, ##p, ##x...\n",
       "3337    [amo, ##xid, ##al, ped, 250, mg, sus, ##p, ##x...\n",
       "3338    [amo, ##xid, ##al, ped, 500, mg, sus, ##p, ##x...\n",
       "3339    [amo, ##xid, ##al, ped, 500, mg, sus, ##p, ##x...\n",
       "3340    [amo, ##xid, ##al, ped, 500, mg, sus, ##p, ##x...\n",
       "3341    [amo, ##xid, ##al, respira, ##torio, 1, g, in,...\n",
       "3342    [amo, ##xid, ##al, respira, ##torio, 1, g, in,...\n",
       "3343    [amo, ##xid, ##al, respira, ##torio, cap, ##s,...\n",
       "3344    [amo, ##xid, ##al, respira, ##torio, compre, #...\n",
       "3345    [amo, ##xid, ##al, respira, ##torio, du, ##o, ...\n",
       "3346    [amo, ##xid, ##al, respira, ##torio, du, ##o, ...\n",
       "3347    [amo, ##xid, ##al, respira, ##torio, ped, 500,...\n",
       "3348    [amo, ##xid, ##al, respira, ##torio, ped, 500,...\n",
       "3349      [amo, ##xi, ##far, ##ma, 1000, mg, comp, x, 16]\n",
       "3350       [amo, ##xi, ##far, ##ma, 1000, mg, comp, x, 8]\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizamos cada descripcion\n",
    "data_MasterProductos[\"token\"] = data_MasterProductos[\"descrip1_descrip2\"].apply(lambda x: tokenizer.tokenize(x))\n",
    "data_MasterProductos[\"token\"].iloc[3330:3351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_maestro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m pares \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m etiquetas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, fila_maestro \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_maestro\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, fila_proveedor \u001b[38;5;129;01min\u001b[39;00m df_proveedor\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     18\u001b[0m         desc_maestro \u001b[38;5;241m=\u001b[39m fila_maestro[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescripcion_limpia\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_maestro' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Función para obtener el embedding de BERT\n",
    "def obtener_embedding(texto):\n",
    "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Promedio de las capas de BERT\n",
    "\n",
    "#Crear pares de descripciones y calcular similitud \n",
    "pares = []\n",
    "etiquetas = []\n",
    "\n",
    "\n",
    "\n",
    "for _, fila_maestro in data_MasterProductos.iterrows():\n",
    "    for _, fila_proveedor in df_proveedor.iterrows():\n",
    "        desc_maestro = fila_maestro[\"descripcion_limpia\"]\n",
    "        desc_proveedor = fila_proveedor[\"descripcion_limpia\"]\n",
    "\n",
    "        # Obtener embeddings de las descripciones\n",
    "        emb_maestro = obtener_embedding(desc_maestro)\n",
    "        emb_proveedor = obtener_embedding(desc_proveedor)\n",
    "\n",
    "        # Calcular la similitud coseno\n",
    "        similitud = cosine_similarity([emb_maestro], [emb_proveedor])[0][0]\n",
    "\n",
    "        # Definir el umbral de similitud\n",
    "        umbral_similitud = 0.85\n",
    "\n",
    "        # Si la similitud es mayor que el umbral, es una coincidencia\n",
    "        if similitud >= umbral_similitud:\n",
    "            etiquetas.append(1)  # Coincidencia positiva\n",
    "        else:\n",
    "            etiquetas.append(0)  # Coincidencia negativa\n",
    "\n",
    "        # Guardar el par de descripciones\n",
    "        pares.append((desc_maestro, desc_proveedor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear el DataFrame de entrenamiento\n",
    "df_entrenamiento = pd.DataFrame(pares, columns=[\"descripcion_maestro\", \"descripcion_proveedor\"])\n",
    "df_entrenamiento[\"etiqueta\"] = etiquetas\n",
    "\n",
    "# Guardar el dataset\n",
    "df_entrenamiento.to_csv(\"dataset_entrenamiento.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
